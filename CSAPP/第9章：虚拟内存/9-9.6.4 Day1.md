- 简单来说，内存无法满足进程需求，所以内存中只保留活动部分（缓存），剩下的放到磁盘里，依靠映射关系访问

由于进程之间共享cpu和主存资源，当进程过多时所需内存超出上限就会导致进程无法运行，也有可能因为跨进程访问内存而导致进程失败。
- 虚拟内存为每个进程提供一个大容量、一致的、私有的地址空间，具有以下能力：
	1. 将主存看作磁盘地址空间中的高速缓存，在主存中只保存活动区域，根据需要在磁盘和主存间来回传送数据，高效运用主存
	2. 为每个进程提供一致的地址空间，简化内存管理
	3. 保护每个进程的地址空间不受其他进程破坏

### 物理和虚拟寻址
1. 主存的地址被组织成一个由M个字节单元组成的数组，每个字节都有唯一的物理地址PA，cpu访问内存最自然的方式就是物理寻址
	![[5156a6b07614c73cf692df8636c61bef.png]]
	- cpu执行加载指令，生成有效物理地址，通过内存总线传递给主存，主存取出指定数量的字节返回给cpu,cpu存在寄存器里
2. cpu通过生成一个虚拟地址VA来访问主存，VA在被传送到内存前先转换成适当的物理地址（该过程叫地址翻译），由cpu中的内存管理单元MMU访问主存查询表（由os管理）来动态翻译
	![[9188098e33280cce0dde801373781319.png]]

### 地址空间
- 是非负整数的有序集合，假设总是线性的（连续）
- cpu从N=2^n个地址的地址空间中生成n位虚拟地址空间{0,1,...,N-1}
- 物理地址空间对应于M个字节{0,1,...,M-1}，假设M=2^m
- **地址空间区分了字节数据与地址属性，意味着每个数据对象都可以从多个地址空间中选择多个独立的地址**

### 虚拟内存VM作为缓存的工具
- 磁盘上数组的内容被缓存在主存中
- 参照其他缓存，磁盘（作为低层）的数据被分割成块，作为与主存（作为高层）的传输单元
- VM系统通过将虚拟内存分割成虚拟页VP（大小固定的块）来适应上述情况，每个页的大小为P=2^p字节，同时物理内存被分割为物理页PP，大小也是P字节

VP始终由以下三部分组成：
1. 未分配的：VM系统还未分配/创建的页。没有任何数据与它们相关联，不占用任何磁盘空间
2. 缓存的：当前已经缓存在物理内存中的已分配页
3. 未缓存的：未缓存在物理内存中的已分配页
![[ceb2d329a146961f5d95372f77f6b166.png]]

#### DRAM缓存
指的是VM系统的缓存，在主存中缓存VP

由于访问速度的差别，DRAM缓存不命中后果严重，为了减小不命中处罚
1. VP往往很大，在4KB～2MB之间
2. DRAM缓存是全相联的（只有一组），所以任何VP（磁盘数据）可以放置在任何PP（缓存行）中
3. 不命中时的替换策略更加复杂
4. 由于磁盘访问时间过长，采用写回，而非直写

#### 页表PT
- VM系统需要判定一个VP是否缓存在DRAM中
	- 是，则判定在哪个PP中
	- 不命中，应该存在磁盘哪个位置，牺牲哪一页
		- 将VP从磁盘复制到DRAM,替换牺牲页

OS、MMU的地址翻译硬件、存在物理内存中的页表将实现上述功能。
1. 页表将VP映射到PP,每次MMU在转换地址时都会读取页表
2. OS负责维护页表，并在磁盘和DRAM之间传送页

页表是页表条目（PTE）的数组，虚拟地址空间中每页在页表中一个固定偏移量下有一个PTE。**PTE与VP数量相等且一一对应**
假设PTE由一个有效位和一个n位地址组成：![[044ddf3f3f30e7c7fc2816cfd8404e53.png]]
- 设置了有效位：
	- 地址字段表示已缓存已分配的VP在DRAM中相应PP的起始位置（VP 1 2 7 4）
- 未设置有效位：
	- 地址非空表示未缓存已分配的VP在磁盘的起始位置（VP 3 6）
	- 地址NULL表示未分配（VP 0 5）
- 由于全相联，任意PP都可以放任意VP

#### 页命中与缺页、分配页
![[e75803062e13a304ca4c5886ddc42f46.png]]
访问VP2
- MMU将虚拟地址翻译成PTE索引
- 由于设置了有效位，MMU将在DRAM中寻找
- 根据物理页号找到PP1


![[b927bdc0812670523ea3e45b69775ac0.png]]访问VP3（DRAM缓存不命中称为缺页）
- CPU使用VP3中的一个字，发现未被缓存
- MMU从内存中读取PTE3,证实未缓存，触发**缺页异常**
- 调用内核中的异常处理程序
- 程序选择牺牲一页（VP4），如果VP4已经被修改过，则写回
- 修改PTE4的有效位和地址字段
- 内核从磁盘中复制VP3到PP3中，设置PTE3的有效位和地址字段，异常处理程序返回
- 重新启动当前指令，重新把地址发送给MMU,完成页命中
![[7c2b51a3c17cbe2e262be654826c4967.png]]

> 大部分系统采用按需页面调度：直到发生不命中，才替换页面


![[56c83b78ca70fb3ac4326744bd7a898f.png]]分配VP5
- 在磁盘上找到一块大小合适的空间，标注为VP5
- 修改PTE5的地址字段，指向该空间

#### 局部性
依赖于局部性，即使VP之和大于DRAM，由于保证了只将程序活动的部分存在DRAM中，对于活动集合的访问不再发生缺页
- 若活动集合太大超出DRAM,则会发生抖动：VP不断进入进出PP,导致变慢


### 虚拟内存VM作为内存管理的工具
实际上，每个进程都有单独的页表，也就意味着每个进程的虚拟地址空间（磁盘）是独立的
![[ec38bbe5b6f1686b2085161da9c9c082.png]]
- 相对的，由于多个VP可以映射在同一个PP上，意味着有共享页面

VM内存管理的优势：
1. 简化链接：独立地址空间允许每个进程的内存映像用相同的基本格式，无需考虑代码和数据的物理内存地址。**一致的格式使得链接器设计简单**，允许生成全链接的EXE,并且EXE可以独立于物理内存的最终位置
2. 简化加载：加载EXE与共享对象文件更加简单。linux加载器为`.text`和`.data`节分配虚拟页，PTE有效位为0,**地址字段指向目标文件的一定偏移处**。复制操作不由加载器完成，在页第一次被引用时，VM系统自动的调入数据页
	- 内存映射：将一组连续的VP映射到任意文件的任意位置
3. 简化共享：非共享部分在OS创建页表之后，VM系统将VP映射到不连续的PP；**对于共享部分，例如`printf`，OS会将各个进程中的对应VP映射到同一个PP**
4. 简化额外内存分配：当一个运行在用户进程中的程序额外要求堆空间时，**OS会分配k个连续的VP,并且映射到k个任意的PP,不要求连续**

### 虚拟内存VM作为内存保护的工具
- 通过添加许可位，**实现进程有限制的访问VP/PP**，VP与PP权限对等
![[d199b3b9bfc8a148262e006c3ef604b3.png]]
举例：`用户模式下的进程i：读VP0；读写VP4；不允许访问VP2`
- 当指令违反许可时，发生一般故障保护（段错误）

### 地址翻译（暂不考虑许可位）
![[1acb8189c2807fd46bea86c60b4b20f0.png]]![[5636834325878004d71836c557f981bc.png]]
- 页面命中：
	1. CPU生成一个VA并且发送给MMU
	2. MMU分割VPN和VPO
	3. VPN指向PTE,故MMU申请访问DRAM中的PTEA（页表在DRAM中）
	4. DRAM返回PTE给MMU
	5. 如果VPN指向的PTE**有效位为1**,则将地址字段的PPN与VPO连接，组成PA，并申请访问DRAM中的指定空间
	6. DRAM返回数据给CPU
	![[5481850868f7be76fd095bcc0869787f.png]]
- 缺页（硬件与OS内核协作）：
	1. 如果VPN指向的PTE**有效位为0**
	2. MMU触发异常，将控制传递给内核中的异常处理程序
	3. 程序确定牺牲页
	4. 如果牺牲页已经被修改，则多一步写回
	5. 程序把新页面调入PP
	6. 修改原页面的有效位、将PPN改为VP的磁盘位置；
	7. 修改新页面的有效位、将地址字段设置为PPN
	8. 程序返回进程，重新执行指令
	9. CPU再次将同一VA发送给MMU
	10. 页面命中
	![[fe5ac40aa2c564a2e27c53d62a7e039f.png]]

#### cache和VM结合使用
- 系统采用VA访问DRAM缓存
- 系统采用PA访问SRAM缓存

以下是cache和VM的结合使用，存储角色从：DRAM->磁盘变成了cache->DRAM![[fafae83d140f7f4f490c2d372027bb42.png]]

#### TLB加速地址翻译
每次CPU产生VA时，MMU就要查询PTE，这样在极端情况下浪费太多时钟周期。
- 系统在MMU中加入了关于PTE的小缓存，称为翻译后备缓冲器TLB
![[ddb836119d90ab7f79ac565d43f2308f.png]]
类比cache，TLB每一行都有一个单个PTE组成的块，行之间的相联度很高
- 中间t位（TLB有T=2^t组）用于组选择和行匹配
- 最高的n-t-p位用于标记

依靠TLB，CPU不需要访问DRAM（页表在这），所以非常快
![[1fdc319b16af2f713f14d5197395dc4b.png]]
1. CPU产生VA
2. MMU根据VPN从TLB中取出PTE
3. 将地址字段的PPN与VPO连接，组成PA，并申请访问DRAM中的指定空间，DRAM返回数据给CPU
4. TLB中没有对应PTE,则从页表总找到PTE放入TLB中（可能覆盖）

#### 多级页表
对于32位地址空间：
- 表示地址4GB
- 每页面4KB
- 每PTE 4B
也需要4MB大小的页表（4GB/4KB x 4B）

通过多级页表，可以减小页表在内存中驻留的大小
![[7b57b521a31e2b577dd57665740fa9b3.png]]
对于上述配置的条件：
- 一级页表中每个PTE负责映射4MB的chunk，所以1K个PTE就足以满足4GB了（一级页表共4KB）
	- 一级页表中PTEi可以为空，从而不会产生二级页表
- 二级页表中每个PTE负责映射4KB的VM：
	- 此时假设VM结构为上图
	- 二级页表中PTEi也可以为空

对于大部分程序来说，根本用不到4GB的VM（因此不需要4MB的页表）
1. 只有一级页表需要在DRAM中；
2. VM系统可以在需要时创建、调入、调出二级页表，只有最常用的二级页表才放在DRAM中

![[13cac9ca3b91e956d89fab6f8a2af656.png]]
k级页表的地址翻译：
- VPNi是第i层页表的索引
- 第i层页表中的每个PTE,都指向下一层某个页表的基址
- 第k层页表的每个PTE包含某个PP的PPN,或者磁盘块的地址（未缓存）
- 多亏了TLB，访问k层PTE实际上开销并不大

#### 端到端的地址翻译
假设有以下条件：
![[cd80a459b4e66e4532cb1e8ce553d199.png]]

1. 由于2^6=64字节，所以低6位是地址偏移
	![[f4727ccfa89eb3c11c5d30d7f5e9d795.png]]
2. TLB：利用VPN进行虚拟寻址，由于有四个组，所以低2位可以作为组索引，剩下6位作为标记位（用来区别可能映射到同一组的不同VPN）下图中标记位是最高两位为0的2位16进制数，故4组x2^(8-2)=256个不同的PTE
	![[1f1706e2ab31b6812cadd9db5599b6fa.png]]
3. 页表：单级设计，总共256个PTE
	![[3bed5aa8390055c8e212c51f92d76a94.png]]
4. cache：12位地址中，每块4字节故CO2位来偏移，16组故CI4位来组索引，剩下6位标记CT
	![[92302667a0d1017e5ba0bdc98141b985.png]]
5. 举例寻找`VA=0x03d4`
	1. MMU，对照上面的一系列表格
		![[103bfb1e8153be0dc802ad9a075d2b93.png]]
	2. cache，对照上面的一系列表格
		![[e81d1d1ca291690a7b1d9efcb0e897ff.png]]


